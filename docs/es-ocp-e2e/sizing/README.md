# Elasticsearch Cluster Sizing

## Profile: Custom (from Sizing Report)

Custom sizing from report (Health: 65/100)

## Source Data

| Metric | Value |
|--------|-------|
| Daily Ingestion | 650.0 GB/day |
| Retention Period | 365 days |
| Workload Type | security |
| Health Score | 65/100 |

## Platform: OpenShift

This configuration is optimized for **OpenShift** deployment.

## Tier Architecture

### Hot Tier (Primary Indexing)
- **Nodes**: 8
- **Memory**: 64Gi per node
- **CPU**: 16 cores per node
- **Storage**: 1800Gi per node (premium)
- **Role**: Active indexing, recent data queries

### Cold Tier (Long-term Storage)
- **Nodes**: 200
- **Memory**: 64Gi per node
- **CPU**: 12 cores per node
- **Storage**: 5000Gi per node (standard)
- **Role**: Historical data, infrequent queries

### Frozen Tier (Searchable Snapshots)
- **Nodes**: 3
- **Memory**: 32Gi per node
- **CPU**: 8 cores per node
- **Cache Storage**: 2400Gi per node (local SSD)
- **Snapshot Repository**: 101,254 GB (remote object storage)
- **Role**: Archive data, on-demand queries via snapshots

## Stack Components

### Kibana
- **Instances**: 4
- **Memory**: 18Gi per instance
- **CPU**: 10 cores per instance

### Fleet Server
- **Instances**: 3
- **Memory**: 24Gi per instance
- **CPU**: 12 cores per instance

## Resource Totals

| Resource | Total |
|----------|-------|
| Nodes | 234 |
| vCPU | 2752.0 cores |
| RAM | 14072.0 GB |
| Local Disk | 1054600.0 GB |
| Snapshot Storage | 101,254 GB |

## Re-sizing with AI Assistant

For adjustments or re-sizing, use the recommended skill:

```bash
# Load the sizing skill
load skill elasticsearch-openshift-sizing-assistant-legacy

# Example prompt:
# "Adjust sizing for increased ingestion to 400 GB/day"
```

## Capacity Planning Guidelines

### Tier Strategy
- **Hot**: 7-14 days of data, fastest queries
- **Cold**: 30-90 days, reduced resources, slower queries
- **Frozen**: 90+ days, minimal local storage, uses snapshots

### Memory Sizing
- JVM heap should be 50% of container memory (max 31GB heap)
- Hot tier: Higher memory for indexing performance
- Frozen tier: Memory for cache, not full dataset

### Storage Strategy
- Hot: Premium/SSD for write throughput
- Cold: Standard storage, larger capacity
- Frozen: Local cache + object storage (S3/Azure Blob/GCS)

---

*Generated by project-initializer sizing integration addon*
*Source: Sizing Report (Health Score: 65/100)*
